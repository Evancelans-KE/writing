{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7515ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp/ipykernel_23964/2180631869.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Import the necessary libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "\n",
    "#Load the data \n",
    "\n",
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "#Define  the image transformation characteristics\n",
    "train_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=train_transforms)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
    "\n",
    "#The mappings\n",
    "\n",
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "\n",
    "#Testing the loads\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "print(len(images[0,2]))\n",
    "plt.imshow(images[0,0])\n",
    "\n",
    "\n",
    "# Training the classifier \n",
    "\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "from collections import OrderedDict    \n",
    "model.classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(25088, 2048)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(2048, 256)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc3', nn.Linear(256, 102)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "print(model)\n",
    "model = model.to('cuda')\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "#Classifier training\n",
    "\n",
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        \n",
    "        \n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "     \n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in validloader:\n",
    "                    inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                    \n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    valid_loss += batch_loss.item()\n",
    "                    \n",
    "                 \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Validation Loss: {valid_loss/len(validloader):.3f}.. \"\n",
    "                  f\"Accuracy: {accuracy/len(validloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "#Network testing\n",
    "\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        logps = model.forward(inputs)\n",
    "        batch_loss = criterion(logps, labels)\n",
    "                    \n",
    "        test_loss += batch_loss.item()\n",
    "                    \n",
    "       \n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "print(f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "\n",
    "#Image processing\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    img_pil = Image.open(image)\n",
    "    img_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = img_transforms(img_pil)\n",
    "    \n",
    "    return image\n",
    "\n",
    "#\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "imshow(process_image(\"flowers/test/1/image_06764.jpg\"))\n",
    "\n",
    "#Predict the class \n",
    "\n",
    "def predict(image_path, model, topk=5):   \n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "    img = process_image(image_path)\n",
    "    img = img.numpy()\n",
    "    img = torch.from_numpy(np.array([img])).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.forward(img.cuda())\n",
    "        \n",
    "    probability = torch.exp(output).data\n",
    "    \n",
    "    return probability.topk(topk)\n",
    "\n",
    "\n",
    "\n",
    "img = \"flowers/test/10/image_07090.jpg\"\n",
    "probability, classes = predict(img, model)\n",
    "print (probability)\n",
    "print (classes)\n",
    "\n",
    "#Then predict\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.subplot(211)\n",
    "\n",
    "index = 1\n",
    "path = test_dir + '/1/image_06743.jpg'\n",
    "\n",
    "probabilities = predict(path, model)\n",
    "image = process_image(path)\n",
    "\n",
    "\n",
    "axs = imshow(image, ax = plt)\n",
    "axs.axis('off')\n",
    "axs.title(cat_to_name[str(index)])\n",
    "axs.show()\n",
    "\n",
    "\n",
    "a = np.array(probabilities[0][0])\n",
    "b = [cat_to_name[str(index+1)] for index in np.array(probabilities[1][0])]\n",
    "\n",
    "N=float(len(b))\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "width = 0.5\n",
    "tickLocations = np.arange(N)\n",
    "\n",
    "\n",
    "ax.bar(tickLocations, a, width, linewidth=4.0, align = 'center')\n",
    "ax.set_xticks(ticks = tickLocations)\n",
    "ax.set_xticklabels(b)\n",
    "ax.set_xlim(min(tickLocations)-0.6,max(tickLocations)+0.6)\n",
    "ax.set_yticks([0.2,0.4,0.6,0.8,1,1.2])\n",
    "ax.set_ylim((0,1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf339b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
